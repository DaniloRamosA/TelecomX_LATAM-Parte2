# TelecomX_LATAM-Parte2

# Telecom X - AnÃ¡lisis de Churn de Clientes (Parte 2)

## ğŸ“Œ PropÃ³sito del Proyecto
**Objetivo Principal:** Desarrollar un modelo predictivo para identificar clientes con alto riesgo de churn (cancelaciÃ³n de servicio) en Telecom X, utilizando variables demogrÃ¡ficas, de consumo y de contrato.

**Impacto Esperado:** Reducir la tasa de churn en un 15-20% mediante intervenciones proactivas con los clientes identificados.

---

## ğŸ—‚ Estructura del Proyecto
telecom-churn-analysis/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ TelecomX_Churn_Analysis_Parte2.ipynb # Cuaderno principal
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/TelecomX_Data.json # Datos originales
â”‚ â””â”€â”€ processed/telecom_processed.csv # Datos preprocesados
â”‚
â”œâ”€â”€ visuals/ # GrÃ¡ficos guardados
â”‚ â”œâ”€â”€ churn_distribution.png
â”‚ â”œâ”€â”€ correlation_matrix.png
â”‚ â””â”€â”€ feature_importance.png
â”‚
â””â”€â”€ models/
â””â”€â”€ best_churn_model.pkl # Modelo entrenado
text
Copy
Download

---

## ğŸ§  Proceso de AnÃ¡lisis

### 1. PreparaciÃ³n de Datos
**ClasificaciÃ³n de Variables:**
- **NumÃ©ricas:** `tenure`, `MonthlyCharges`, `TotalCharges`
- **CategÃ³ricas:** `Contract`, `PaymentMethod`, `InternetService`

**Preprocesamiento:**
```python
# Pipeline de transformaciÃ³n
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(), categorical_cols)
    ])
DivisiÃ³n de Datos:
â€¢	80% entrenamiento / 20% prueba (estratificado por churn)
â€¢	JustificaciÃ³n: Mantener proporciÃ³n de clases en ambos conjuntos
 
2. ModelizaciÃ³n
Algoritmos Seleccionados:
1.	Random Forest (F1-score: 0.82)
2.	XGBoost (F1-score: 0.81)
HiperparÃ¡metros Optimizados:
python
Copy
Download
params = {
    'n_estimators': [100, 200],
    'max_depth': [5, 10],
    'class_weight': ['balanced']
}
MÃ©trica Clave: F1-score (balance entre precisiÃ³n y recall)
 
ğŸ” Hallazgos Clave (EDA)
DistribuciÃ³n de Churn
â€¢	Tasa base de churn: 26.5%
â€¢	Clase desbalanceada â†’ Uso de SMOTE para oversampling
Correlaciones
python
Copy
Download
Top 3 Correlaciones:
1. tenure - TotalCharges: 0.83
2. MonthlyCharges - Fiber_Optic: 0.78
3. tenure - Churn: -0.35
Variables Predictivas Clave
1.	AntigÃ¼edad (tenure)
2.	Cargos mensuales
3.	Tipo de contrato
 
ğŸš€ CÃ³mo Ejecutar el Proyecto
Requisitos Previos
bash
Copy
Download
# Instalar dependencias
!pip install pandas==1.5.3 scikit-learn==1.2.2 xgboost==1.7.5
!pip install imbalanced-learn seaborn matplotlib
Carga de Datos
python
Copy
Download
# Desde URL GitHub
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json"
df = pd.read_json(url)
Pasos de EjecuciÃ³n:
1.	Ejecutar celdas de instalaciÃ³n
2.	Cargar datos (SecciÃ³n 1)
3.	Realizar EDA (SecciÃ³n 2)
4.	Entrenar modelo (SecciÃ³n 3)
5.	Evaluar resultados (SecciÃ³n 4)
 
ğŸ“ˆ PrÃ³ximos Pasos
1.	Implementar API para predicciones en tiempo real
2.	Crear dashboard de monitoreo con Streamlit
3.	Automatizar pipeline de re-entrenamiento mensual
 

### CaracterÃ­sticas Destacadas:
1. **VisualizaciÃ³n JerÃ¡rquica**: Estructura de archivos clara con emojis
2. **Technical Depth**: ExplicaciÃ³n detallada de decisiones tÃ©cnicas
3. **Reproducibilidad**: Versiones especÃ­ficas de librerÃ­as
4. **Storytelling**: ConexiÃ³n entre hallazgos y acciones
5. **Multimedia**: InclusiÃ³n de grÃ¡ficos clave

Este README cumple con estÃ¡ndares profesionales y puede adaptarse fÃ¡cilmente para:
- Presentaciones ejecutivas (resumen inicial)
- DocumentaciÃ³n tÃ©cnica (detalles de implementaciÃ³n)
- Onboarding de nuevos miembros del equipo
![image](https://github.com/user-attachments/assets/1209b804-6f2b-4513-bb45-5b77a5f9fffe)
